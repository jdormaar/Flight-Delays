{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Exploratory Data Analysis\n",
        "----\n",
        "\n",
        "\n",
        "\n",
        "### Lighthouse Labs, Midterm Project Project - Predicting Flight Delays.\n",
        "\n",
        "##### January 13, 2023. Terre Leung, Tetiana Fesenko, and Jamie Dormaar\n",
        "\n",
        "---\n",
        "\n",
        "_Use this notebook to get familiar with the datasets we have. There is 10 questions we need to answer during the EDA._\n",
        "\n",
        "\n",
        "_We shouldn't limit our EDA to these 10 questions. Let's be creative :)._"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime as dt\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "sns.set_theme()\n",
        "\n",
        "from scipy import stats\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import os\n",
        "import json\n",
        "import requests\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load data tables:\n",
        "flights_initial_500000_records    = pd.read_csv('../data/flights_initial_500000_records.csv', delimiter= ',')\n",
        "flights_delay_dates_all_records   = pd.read_csv('../data/flights_delay_dates_all_records.csv', delimiter= ',')\n",
        "flights_random_100000_records     = pd.read_csv('../data/flights_random_100000_records.csv', delimiter= ',')\n",
        "#flights_random_5000_records       = pd.read_csv('../data/flights_random_5000_records.csv', delimiter= ',')\n",
        "flights_test_all_records          = pd.read_csv('../data/flights_test_all_records.csv', delimiter= ',')\n",
        "fuel_consumption_all_records      = pd.read_csv('../data/fuel_consumption_all_records.csv', delimiter= ',')\n",
        "passengers_initial_300000_records = pd.read_csv('../data/passengers_initial_300000_records.csv', delimiter= ',')\n",
        "# flights_usa = pd.read_csv('../data/usa_flights2.csv', delimiter= ',')  # Terre is there a new csv to go with this one?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save working copies of the data:\n",
        "df_fl_init    = flights_initial_500000_records.copy()\n",
        "df_fl_delays  = flights_delay_dates_all_records.copy()\n",
        "df_fl_smpl1   = flights_random_100000_records.copy()\n",
        "#df_fl_smpl2   = flights_random_5000_records.copy()\n",
        "df_fl_test    = flights_test_all_records.copy()\n",
        "df_fc         = fuel_consumption_all_records.copy()\n",
        "df_pa_init    = passengers_initial_300000_records.copy()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Set your session working table to temp variable df:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = df_fl_smpl1.copy()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### SAVE a session timestamp to label the saved outputs: \n",
        ">(Optional: this can be useful if you want to help keep your files organized)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "tag = 'smpl_100K_' # option with leading name            'Jamie_'\n",
        "# tag = ''\n",
        "# dt = dt.now().time().strftime(f'%b%d_%H%M')   # 'Jan01_1704'\n",
        "# dt = dt.now().time().strftime(f'%b%-d_%H%M')  # 'Jan1_1708'\n",
        "# dt = dt.now().time().strftime(f'%a_%H%M')        # 'Mon_1710'\n",
        "dt = ''\n",
        "session = f'{tag}{dt}'"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### SETUP: A first look at tables:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# flights_initial_500000_records\n",
        "print(f'\\nflights_initial_500000_records.shape: {flights_initial_500000_records.shape}')\n",
        "display(flights_initial_500000_records.head())\n",
        "\n",
        "# flights_delay_dates_all_records\n",
        "print(f'\\nflights_delay_dates_all_records.shape: {flights_delay_dates_all_records.shape}')\n",
        "display(flights_delay_dates_all_records.head())\n",
        "\n",
        "# flights_random_100000_records\n",
        "print(f'\\nflights_random_100000_records.shape: {flights_random_100000_records.shape}')\n",
        "display(flights_random_100000_records.head())\n",
        "\n",
        "# flights_test_all_records\n",
        "print(f'\\nflights_test_all_records.shape: {flights_test_all_records.shape}')\n",
        "display(flights_test_all_records.head())\n",
        "\n",
        "# fuel_consumption_all_records\n",
        "print(f'\\nfuel_consumption_all_records.shape: {fuel_consumption_all_records.shape}')\n",
        "display(fuel_consumption_all_records.head())\n",
        "\n",
        "# passengers_initial_300000_records\n",
        "print(f'\\npassengers_initial_300000_records.shape: {passengers_initial_300000_records.shape}')\n",
        "display(passengers_initial_300000_records.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### NOTE: Missing Data content for each of the four data tables.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check for nulls:\n",
        "# flights Table percent Null content:\n",
        "df_fl_init_nulls = df_fl_init.isnull().sum().sort_values(ascending= False)\n",
        "percent = (df_fl_init.isnull().sum()/df_fl_init.isnull().count()).sort_values(ascending = False)\n",
        "df_fl_init_missing_data = pd.concat(\n",
        "    [df_fl_init_nulls, percent]\n",
        "  , axis=1\n",
        "  , keys=['Total', 'Percent']\n",
        "  , verify_integrity= True\n",
        ")\n",
        "print(f'\\nflights_missing_data.head(20)')\n",
        "display(df_fl_init_missing_data.head(20))\n",
        "\n",
        "# flights_test Table percent Null content:\n",
        "df_fl_test_nulls = df_fl_test.isnull().sum().sort_values(ascending= False)\n",
        "percent = (df_fl_test.isnull().sum()/df_fl_test.isnull().count()).sort_values(ascending = False)\n",
        "df_fl_test_missing_data = pd.concat(\n",
        "    [df_fl_test_nulls, percent]\n",
        "  , axis=1\n",
        "  , keys=['Total', 'Percent']\n",
        "  , verify_integrity= True\n",
        ")\n",
        "print(f'\\nflights_test_missing_data.head(20)')\n",
        "display(df_fl_test_missing_data.head(20))\n",
        "\n",
        "# fuel_consumption Table percent Null content:\n",
        "df_fc_nulls = df_fc.isnull().sum().sort_values(ascending= False)\n",
        "percent = (df_fc.isnull().sum()/df_fc.isnull().count()).sort_values(ascending = False)\n",
        "df_fc_missing_data = pd.concat(\n",
        "    [df_fc_nulls, percent]\n",
        "  , axis=1\n",
        "  , keys=['Total', 'Percent']\n",
        "  , verify_integrity= True\n",
        ")\n",
        "print(f'\\nfuel_consumption_missing_data.head(20)')\n",
        "display(df_fc_missing_data.head(20))\n",
        "\n",
        "# passengers Table percent Null content:\n",
        "df_pa_init_nulls = df_pa_init.isnull().sum().sort_values(ascending= False)\n",
        "percent = (df_pa_init.isnull().sum()/df_pa_init.isnull().count()).sort_values(ascending = False)\n",
        "df_pa_init_missing_data = pd.concat(\n",
        "    [df_pa_init_nulls, percent]\n",
        "  , axis=1\n",
        "  , keys=['Total', 'Percent']\n",
        "  , verify_integrity= True\n",
        ")\n",
        "print(f'\\npassengers_missing_data.head(20)')\n",
        "display(df_pa_init_missing_data.head(20))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### NOTE: Differences between flights, and flights_test table data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "flights_columns = df_fl_init.columns\n",
        "flights_columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "flights_test_columns = df_fl_test.columns\n",
        "flights_test_columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fl_test_exclusion = df_fl_init[df_fl_init.columns[~df_fl_init.columns.isin([flights_test_columns])]]\n",
        "fl_test_exclusion.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### ANALYZE: Arrival delay details in the flights table:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### **Task 1**: \n",
        "\n",
        "1. Test the hypothesis that the delay is from Normal distribution. \n",
        "1. And, that the **mean** of the arrival delays is 0. \n",
        "1. Be careful about the outliers.\n",
        "\n",
        ">##### TASK 1.1: Test the hypothesis that the delay is from Normal distribution. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df[['arr_delay']].value_counts().sort_values(ascending=False).head(20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df['arr_delay'].describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The `stats` package from the `scipy` module will test the Null hypothesis that the data is normally distributed.\n",
        "If the resulting p value is > than 0.05 we can assume the data is distributed normally with high statistical probability."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from scipy import stats\n",
        "stat, p = stats.shapiro(df['arr_delay'])\n",
        "print('%0.15f' % p, stat)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The statistical calculation above printed the following warning:\n",
        "```\n",
        "UserWarning: p-value may not be accurate for N > 5000.\n",
        "```\n",
        "Smaller samples taken to correct for this inaccuracy:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Sample a subset:\n",
        "x = df.sample(1000)\n",
        "len(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Rerun Shapiro Wilk Normality Test:\n",
        "stat, p = stats.shapiro(x['arr_delay'])\n",
        "print('%0.15f' % p, stat)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The data appears to indeed be normally distributed.\n",
        "\n",
        ">##### TASK 1.3: Managing outliers.\n",
        "\n",
        "##### VISUALIZE: Arrival delay distribution, and manage outliers:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.hist(df['arr_delay'], bins=500)\n",
        "\n",
        "\n",
        "plt.xlabel('Delay Time (min)')\n",
        "plt.title('Arrival Delay Distribution')\n",
        "plt.xlim(-50, 50)\n",
        "plt.ylim(0, 10000)\n",
        "\n",
        "plt.savefig(f'../Images/Arrival_delay_distn_{session}.png')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Outlier detection:\n",
        "sns.boxplot(data= df, x='arr_delay', whis= 2.5)\n",
        "\n",
        "plt.savefig(f'../Images/Arrival_delay_outliers_boxplot_{session}.png')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Manually chosen outlier range limits:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Define and remove the outliers by a chosen parameter:\n",
        "# max_delay = 100\n",
        "# outliers    = df_fl_init[df_fl_init['arr_delay'] > max_delay]\n",
        "# df_fl_clean = df_fl_init[df_fl_init['arr_delay'] < max_delay]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "or using the standard 1.5 * IQR:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Instantiate the Arrival Delays:\n",
        "delays = df['arr_delay']\n",
        "\n",
        "# Define the quantiles of the delay distribution:\n",
        "Q1 = delays.quantile(0.25)\n",
        "Q3 = delays.quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "\n",
        "# Define the outlier thresholds\n",
        "min_threshold = (Q1 - 1.5 * IQR)\n",
        "max_threshold = (Q3 + 1.5 * IQR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_clean = df[~((delays < min_threshold)|(delays > max_threshold))]\n",
        "df_clean.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sns.boxplot(x=df_clean['arr_delay'])\n",
        "\n",
        "#SAVE boxplot of clean delay distribution:\n",
        "plt.savefig(f'../Images/Arrival_delay_boxplot_{session}.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# fig, ax1 = plt.subplots()\n",
        "\n",
        "# ax1 = fl_df_clean.plot()\n",
        "# ax2 = fl_df.plot()\n",
        "\n",
        "# ax1.hist([y1, y2])\n",
        "# ax1.set_xlim(-10,10)\n",
        "# fig, (ax1, ax2) = plt.subplots(1, 2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### **Task 2**: Is average/median monthly delay different during the year? If yes, which are months with the biggest delays and what could be the reason?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convert fl_date from string to datetime data type\n",
        "df_clean[['fl_date']] = df_clean[['fl_date']].apply(pd.to_datetime)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_clean['date'] = df_clean['fl_date'].dt.date\n",
        "df_clean['year'] = df_clean['fl_date'].dt.year\n",
        "df_clean['month'] = df_clean['fl_date'].dt.month\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(df_clean[['year', 'month', 'fl_date', 'date']].dtypes)\n",
        "display(df_clean[['year', 'month', 'fl_date', 'date']].head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_clean[['month', 'year', 'arr_delay']].groupby(['year', 'month']).describe()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ">NOTE: This was the point where we discovered that our initial sample of 500000 records we collected from the source flights table turned out to only include records from 2 months in 2018.  So evidently the source table is sorted by date."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_clean.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Separate the data for easier viewing re annual delay trends:\n",
        "df_clean_2018 = df_clean[df_clean['year']==2018]\n",
        "df_clean_2019 = df_clean[df_clean['year']==2019]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_clean_2018.groupby(['month']).agg({'arr_delay': np.mean}).sort_values('arr_delay', ascending=False)\n",
        "# df_delays_2018.groupby(['year', 'month']).agg(({'arr_delay': np.median}))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_clean_2019.groupby('month').agg({'arr_delay': np.mean}).sort_values('arr_delay', ascending=False)\n",
        "# df_delays_2019.groupby(['year', 'month']).agg(({'arr_delay': np.median}))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sns.scatterplot(data=df_clean_2019, x=\"month\", y=\"arr_delay\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# month\n",
        "var = 'month'\n",
        "data = df_clean_2019[['arr_delay',var]]\n",
        "f, ax = plt.subplots(figsize=(8, 6))\n",
        "fig = sns.boxplot(x=var, y=\"arr_delay\", data=data)\n",
        "fig.axis(ymin=-100, ymax=100)\n",
        "\n",
        "plt.savefig(f'../Images/Arrival_delays_monthly_boxplot_{session}.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_clean_2019.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pass_columns = sorted(list(df_pa_init.columns))\n",
        "# pass_columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# df['origin_city_name'].value_counts()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "There doesn't appear to be an observable trend.\n",
        "\n",
        "Perhaps if we isolate the flights with a single country as a destination, for example the US:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_clean['origin_region_code'] = df_clean['origin_city_name'].str[-2:]\n",
        "df_clean['dest_region_code'] = df_clean['dest_city_name'].str[-2:]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "us_states = [\n",
        "    'AL', 'AK', 'AZ', 'AR', 'CA', 'CO'\n",
        "  , 'CT', 'DE', 'DC', 'FL', 'GA', 'HI'\n",
        "  , 'ID', 'IL', 'IN', 'IA', 'KS', 'KY'\n",
        "  , 'LA', 'ME', 'MD', 'MA', 'MI', 'MN'\n",
        "  , 'MS', 'MO', 'MT', 'NE', 'NV', 'NH'\n",
        "  , 'NJ', 'NM', 'NY', 'NC', 'ND', 'OH'\n",
        "  , 'OK', 'OR', 'PA', 'RI', 'SC', 'SD'\n",
        "  , 'TN', 'TX', 'UT', 'VT', 'VA', 'WA'\n",
        "  , 'WV', 'WI', 'WY'\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_us = df_clean[df_clean['dest_region_code'].isin(us_states)]\n",
        "df_us.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# month\n",
        "var = 'month'\n",
        "data = df_us[['arr_delay',var]]\n",
        "f, ax = plt.subplots(figsize=(8, 6))\n",
        "fig = sns.boxplot(x=var, y=\"arr_delay\", data=data)\n",
        "fig.axis(ymin=-60, ymax=60)\n",
        "\n",
        "plt.savefig(f'../Images/Arr_delays_monthly_boxplot_US_{session}.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_us[['month', 'arr_delay']].groupby('month').median().sort_values('arr_delay')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### **Task 3**: Does the weather affect the delay? \n",
        "Use the API to pull the weather information for flights. There is no need to get weather for ALL flights. We can choose the right representative sample. Let's focus on four weather types:\n",
        "\n",
        "[Local Historical Weather API, WWO](https://www.worldweatheronline.com/weather-api/api/docs/historical-weather-api.aspx)\n",
        "- sunny\n",
        "- cloudy\n",
        "- rainy\n",
        "- snow.\n",
        "Test the hypothesis that these 4 delays are from the same distribution. If they are not, which ones are significantly different?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# NOTE: would like to increase location precision later with lat/long coords of the dest_airport_id later\n",
        "# For now will approximate with dest_city_name and \n",
        "dest_cities = list(df_clean['dest_city_name'])\n",
        "arr_date = list(df_clean['date'])\n",
        "arr_time = list(df_clean['arr_time'])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The `arr_time_code` number will be used to index the correct weather type according to the flight arr_time:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "arr_time_code = []\n",
        "for i in arr_time:\n",
        "    if i <= 150:\n",
        "      arr_time_code.append(0)\n",
        "    elif i <= 450:\n",
        "      arr_time_code.append(1)\n",
        "    elif i <= 750:\n",
        "      arr_time_code.append(2)\n",
        "    elif i <= 1050:\n",
        "      arr_time_code.append(3)\n",
        "    elif i <= 1350:\n",
        "      arr_time_code.append(4)\n",
        "    elif i <= 1650:\n",
        "      arr_time_code.append(5)\n",
        "    elif i <= 1950:\n",
        "      arr_time_code.append(6)\n",
        "    elif i <= 2250:\n",
        "      arr_time_code.append(7)\n",
        "    else:\n",
        "      arr_time_code.append(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(dest_cities[0])\n",
        "print(arr_date[0])\n",
        "print(arr_time[0])\n",
        "print(arr_time_code[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def WWO_API_weather_type(city, date, time):\n",
        "  '''\n",
        "  input:\n",
        "  output:  \n",
        "  '''\n",
        "  api_key = os.environ['WEATHER_API_KEY']\n",
        "  params = {\n",
        "    'q': city\n",
        "    , 'date': date\n",
        "    , 'format': 'json'\n",
        "    , 'key': api_key\n",
        "  }\n",
        "\n",
        "  wwo_url = f'https://api.worldweatheronline.com/premium/v1/past-weather.ashx?'\n",
        "  wwoHxWeather_json = requests.get(wwo_url, params=params).json()\n",
        "\n",
        "  list_of_dict = []\n",
        "  dest_site = wwoHxWeather_json['data']['weather'][0]['hourly']\n",
        "\n",
        "  weather_dict = {\n",
        "      'weather_type':   dest_site[time]['weatherDesc'][0]['value']\n",
        "  }\n",
        "  list_of_dict.append(weather_dict)\n",
        "  return pd.DataFrame(list_of_dict)\n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_weather_desc = WWO_API_weather_type('Aberdeen, SD', '2018-01-01', 4)\n",
        "test_weather_desc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Create list of tiny dfs:\n",
        "# weather_type_list = []\n",
        "# for i in range(df_clean.shape[0]):\n",
        "#   city_x = dest_cities[i]\n",
        "#   date_x = arr_date[i]\n",
        "#   time_x = arr_time_code[i]\n",
        "#   x = WWO_API_weather_type(city_x, date_x, time_x)\n",
        "#   weather_type_list.append(x)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "I stopped the API function loop after 119min which only accumulated approx 21.8% of our data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Confirm equal lengths:  \n",
        "# print(len(weather_type_list))\n",
        "# print(len(dest_cities))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Concatenate the list of dfs to one:\n",
        "\n",
        "# df_weather_type = pd.DataFrame()\n",
        "# df_x = pd.DataFrame()\n",
        "\n",
        "# for x in weather_type_list:\n",
        "#   df_x = pd.concat([df_weather_type, x])\n",
        "#   df_weather_type = df_x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# df_clean.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Create a truncated version of the df_clean to at least save what we have:\n",
        "# temp = df_clean.copy()\n",
        "# temp = temp.reset_index()\n",
        "# temp.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# df_clean_trunc = temp.loc[0:19702, :]\n",
        "# df_clean_trunc.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# df_weather_type.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# len(list(df_weather_type['weather_type']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Add the new column to working df:\n",
        "# df_clean_trunc['weather'] = list(df_weather_type['weather_type'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Confirm the weather type in df:\n",
        "# df_clean_trunc.weather.head()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### SAVE new version of df_clean with weather_types:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# df_clean_trunc.to_csv(f'../data/flights_clean_df{session}.csv', index= False)\n",
        "df_clean_trunc = pd.read_csv('../data/flights_clean_dfsmpl_100K_.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# \n",
        "var = 'weather'\n",
        "data = df_clean_trunc[['arr_delay',var]]\n",
        "\n",
        "f, ax = plt.subplots(figsize=(8, 6))\n",
        "fig = sns.boxplot(x=var, y=\"arr_delay\", data=data)\n",
        "fig.axis(ymin=-60, ymax=60)\n",
        "\n",
        "plt.savefig(f'../Images/Arr_delays_weather_type_boxplot_{session}.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def WWO_API_aux_weather(city, date, time):\n",
        "  '''\n",
        "  input: This function requires 3 input variables. \n",
        "    1. city: acceptable format includes:         # string data type\n",
        "        • City Name\n",
        "        • City Name, State (US only)\n",
        "        • City Name, State, Country\n",
        "        • City Name, Country\n",
        "        • IP address: XXX.XXX.XXX.XXX\n",
        "        • Postal Code (UK or Canada), Zipcode (US)\n",
        "        • Latitude and longitude in decimal degrees\n",
        "    2. date: \n",
        "  output:  \n",
        "  '''\n",
        "  api_key = os.environ['WEATHER_API_KEY']\n",
        "  params = {\n",
        "    'q': city\n",
        "    , 'date': date\n",
        "    , 'format': 'json'\n",
        "    , 'key': api_key\n",
        "  }\n",
        "\n",
        "  wwo_url = f'https://api.worldweatheronline.com/premium/v1/past-weather.ashx?'\n",
        "  wwoHxWeather_json = requests.get(wwo_url, params=params).json()\n",
        "\n",
        "  list_of_dict = []\n",
        "  for i in wwoHxWeather_json['data']['weather'][0]:\n",
        "    weather = wwoHxWeather_json['data']['weather'][0]\n",
        "    hourly = wwoHxWeather_json['data']['weather'][0]['hourly']\n",
        "\n",
        "    weather_dict = {\n",
        "          'max_temp_C':           weather['maxtempC']\n",
        "        , 'min_temp_C':           weather['mintempC']\n",
        "        , 'avg_temp_C':           weather['avgtempC']\n",
        "        , 'total_snow_cm':        weather['totalSnow_cm']\n",
        "        , 'sun_hour':             weather['sunHour']\n",
        "        , 'uv_index':             weather['uvIndex']\n",
        "        , 'arr_wind_chill_C':     hourly[time]['WindChillC']\n",
        "        , 'arr_wind_gust_Kmph':   hourly[time]['WindGustKmph']\n",
        "        , 'arr_cloud_cover':      hourly[time]['cloudcover']\n",
        "        , 'arr_precip_MM':        hourly[time]['precipMM']\n",
        "        , 'arr_pressure':         hourly[time]['pressure']\n",
        "        , 'arr_temp_C':           hourly[time]['tempC']\n",
        "        , 'arr_time':             hourly[time]['time']\n",
        "        , 'arr_uv_index':         hourly[time]['uvIndex']\n",
        "        , 'arr_visibility':       hourly[time]['visibility']\n",
        "        , 'arr_weather_code':     hourly[time]['weatherCode']\n",
        "        , 'arr_wind_dir_16Point': hourly[time]['winddir16Point']\n",
        "        , 'arr_wind_dir_degree':  hourly[time]['winddirDegree']\n",
        "        , 'arr_wind_speed_Kmph':  hourly[time]['windspeedKmph']\n",
        "        , 'arr_weather_type':     hourly[time]['weatherDesc'][0]['value']\n",
        "    }\n",
        "  list_of_dict.append(weather_dict)\n",
        "  return pd.DataFrame(list_of_dict)\n",
        "\n",
        "    "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### TEST API function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# NOTE: would like to increase location precision later with lat/long coords of the dest_airport_id later\n",
        "# For now will approximate with dest_city_name and state code.\n",
        "dest_cities = list(df_clean['dest_city_name'])\n",
        "arr_date = list(df_clean['date'])\n",
        "arr_time = list(df_clean['arr_time'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_aux = WWO_API_aux_weather('Aberdeen, SD', '2018-01-01', 4)\n",
        "test_aux"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# df_test = pd.DataFrame(test['data']['weather'])\n",
        "# list(df_test.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# hourly_columns = sorted(list(df_test_hourly.columns))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# df_test_hourly = pd.json_normalize(df_test['hourly'][0])\n",
        "# df_test_hourly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "arr_time_code = []\n",
        "for i in arr_time:\n",
        "    if i <= 150:\n",
        "      arr_time_code.append(0)\n",
        "    elif i <= 450:\n",
        "      arr_time_code.append(1)\n",
        "    elif i <= 750:\n",
        "      arr_time_code.append(2)\n",
        "    elif i <= 1050:\n",
        "      arr_time_code.append(3)\n",
        "    elif i <= 1350:\n",
        "      arr_time_code.append(4)\n",
        "    elif i <= 1650:\n",
        "      arr_time_code.append(5)\n",
        "    elif i <= 1950:\n",
        "      arr_time_code.append(6)\n",
        "    elif i <= 2250:\n",
        "      arr_time_code.append(7)\n",
        "    else:\n",
        "      arr_time_code.append(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### TEST API function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# test = WorldWeatherOnlineAPI('Aberdeen, SD', '2018-01-01', 6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# df_test = pd.DataFrame(test['data']['weather'])\n",
        "# list(df_test.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# hourly_columns = sorted(list(df_test_hourly.columns))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# df_test_hourly = pd.json_normalize(df_test['hourly'][0])\n",
        "# df_test_hourly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# def WWO_API_weather_json(city, date):\n",
        "#   '''\n",
        "#   input:\n",
        "#   output:  \n",
        "#   '''\n",
        "#   api_key = 5f2766a2052b46e284e45545231101\n",
        "#   params = {\n",
        "#     'q': city\n",
        "#     , 'date': date\n",
        "#     , 'format': 'json'\n",
        "#     , 'key': api_key\n",
        "#   }\n",
        "\n",
        "#   wwo_url = f'https://api.worldweatheronline.com/premium/v1/past-weather.ashx?'\n",
        "#   wwoHxWeather_json = requests.get(wwo_url, params=params).json()\n",
        "\n",
        "#   list_of_dict = []\n",
        "#   dest_site = wwoHxWeather_json\n",
        "#   list_of_dict.append(weather_dict)\n",
        "\n",
        "#   return list_of_dict\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### **Task 4**: How taxi times changing during the day? Does higher traffic lead to bigger taxi times?"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Handling Outliers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_clean"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Let's look at a boxplot of our target variable (taxi_out) to identify any outliers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ax = sns.boxplot(x=df_clean[\"taxi_out\"])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "Q1 = df[\"taxi_out\"].quantile(0.25)\n",
        "Q3 = df[\"taxi_out\"].quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "\n",
        "bound = Q3 + 1.5 * IQR\n",
        "print(f'The upper bound time limit for taxi time is : {bound}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ax = sns.boxplot(x=df_clean[\"taxi_in\"])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "Q1 = df[\"taxi_in\"].quantile(0.25)\n",
        "Q3 = df[\"taxi_in\"].quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "\n",
        "bound = Q3 + 1.5 * IQR\n",
        "print(f'The upper bound time limit for taxi time is : {bound}')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "# Months"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sns.set_style('darkgrid')\n",
        "ax = sns.countplot(x=\"month\", data=df_clean)\n",
        "ax.set_title('Month Counts');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "month_grouped = df_clean.groupby(['month'])['taxi_out'].mean()\n",
        "\n",
        "month_grouped = month_grouped.reset_index()\n",
        "\n",
        "ax = sns.barplot(x='month', y='taxi_out', data=month_grouped, color='#45B39D');\n",
        "\n",
        "ax.set_title('Taxi-Out time by Month');\n",
        "ax.set_ylabel('Average Taxi-Out time (Minutes)');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "month_grouped = df_clean.groupby(['month'])['taxi_in'].mean()\n",
        "\n",
        "month_grouped = month_grouped.reset_index()\n",
        "\n",
        "ax = sns.barplot(x='month', y='taxi_in', data=month_grouped, color='#45B39D');\n",
        "\n",
        "ax.set_title('Taxi-In time by Month');\n",
        "ax.set_ylabel('Average Taxi-Out time (Minutes)');"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Let's check Departure Time vs Taxi Out \n",
        "# AND Arrival Time vs Taxi In"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_clean.columns\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Let's access the dep_time and arr_time columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_clean.loc[0:5,[\"dep_time\",\"arr_time\"]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# The data has some NaN values, so let's clean them up and create a new df_clean_departure_time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_clean_departure_time = df_clean[df_clean.dep_time.notnull()]\n",
        "df_clean_departure_time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_clean_departure_time[\"dep_time_hour\"] = df_clean_departure_time[\"dep_time\"].apply(lambda x: str(int(x))[:-2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Let's create a Boxplot to see the relations between the hour of the day and the taxi_out timing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sns.boxplot(data=df_clean_departure_time, x=\"dep_time_hour\", y = \"taxi_out\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_clean_departure_time[\"dep_time\"].apply(lambda x: str(int(x))[:-2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# The data has some NaN values, so let's clean them up and create a new df_clean_arrival_time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_clean_arrival_time = df_clean[df_clean.arr_time.notnull()]\n",
        "df_clean_arrival_time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Clean the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_clean_arrival_time[\"arr_time\"].apply(lambda x: str(int(x))[:-2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_clean_arrival_time[\"arr_time_hour\"] = df_clean_arrival_time[\"arr_time\"].apply(lambda x: str(int(x))[:-2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Let's create a Boxplot to see the relations between the hour of the day and the taxi_in timing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sns.boxplot(data=df_clean_arrival_time, x=\"arr_time_hour\", y = \"taxi_in\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### **Task 5**: What is the average percentage of delays that is already created before departure? (aka are arrival delays caused by departure delays?) Are airlines able to lower the delay during the flights?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "flights_usa[['fl_date']] = flights_usa[['fl_date']].apply(pd.to_datetime)\n",
        "flights_usa['fl_date']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "flights_usa['year'] = flights_usa['fl_date'].dt.year\n",
        "flights_usa['month'] = flights_usa['fl_date'].dt.month"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#See the distributions\n",
        "flights_usa[['year', 'month']].value_counts().sort_index(ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "flights_usa['state'] = flights_usa['origin_city_name'].str[-2:]\n",
        "flights_usa['late_arr'] = (flights_usa['arr_delay'] > 0).astype(int)\n",
        "flights_usa['late_dep'] = (flights_usa['dep_delay'] > 0).astype(int)\n",
        "flights_usa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "flights_usa['speed'] = flights_usa['distance']/flights_usa['air_time']\n",
        "no_dep_delay = flights_usa[flights_usa['late_dep'] == 0]\n",
        "yes_dep_delay = flights_usa[flights_usa['late_dep'] == 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#If there is no departure delay, there is a 15% chance of late arrival\n",
        "no_dep_delay['late_arr'].mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#If there is a departure delay, there is a 73% chance of late arrival\n",
        "yes_dep_delay['late_arr'].mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### **Task 6**: How many states cover 50% of US air traffic? "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "top_8 = flights_usa['state'].value_counts().head(8)\n",
        "top_8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "total_flight = flights_usa['origin_city_name'].count()\n",
        "total_flight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#These 8 states cover 53% of the flight\n",
        "top_8.sum()/total_flight"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### **Task 7**: Test the hypothesis whether planes fly faster when there is the departure delay? "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Mean of planes speed without departure delay\n",
        "no_dep_delay['speed'].mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Mean of planes speed with departure delay\n",
        "yes_dep_delay['speed'].mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### **Task 8**: When (which hour) do most 'LONG', 'SHORT', 'MEDIUM' haul flights take off?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### **Task 9**: Find the top 10 the bussiest airports. Does the biggest number of flights mean that the biggest number of passengers went through the particular airport? How much traffic do these 10 airports cover?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### **Task 10**: Do bigger delays lead to bigger fuel comsumption per passenger? \n",
        "We need to do four things to answer this as accurate as possible:\n",
        "- Find out average monthly delay per air carrier (monthly delay is sum of all delays in 1 month)\n",
        "- Find out distance covered monthly by different air carriers\n",
        "- Find out number of passengers that were carried by different air carriers\n",
        "- Find out total fuel comsumption per air carrier.\n",
        "\n",
        "Use this information to get the average fuel comsumption per passenger per km. Is this higher for the airlines with bigger average delays?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
