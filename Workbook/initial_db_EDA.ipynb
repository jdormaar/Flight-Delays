{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Database EDA\n",
    "----\n",
    "\n",
    "\n",
    "\n",
    "### Lighthouse Labs, Midterm Project Project - Predicting Flight Delays.\n",
    "\n",
    "##### January 13, 2023. Terre Leung, Tetiana Fesenko, and Jamie Dormaar\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime as dt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data tables:\n",
    "# flights_initial_500000_records    = pd.read_csv('../data/flights_initial_500000_records.csv', delimiter= ',')\n",
    "# flights_delay_dates_all_records   = pd.read_csv('../data/flights_delay_dates_all_records.csv', delimiter= ',')\n",
    "flights_random_100000_records     = pd.read_csv('../data/flights_random_100000_records.csv', delimiter= ',')\n",
    "# flights_random_5000_records       = pd.read_csv('../data/flights_random_5000_records.csv', delimiter= ',')\n",
    "flights_test_all_records          = pd.read_csv('../data/flights_test_all_records.csv', delimiter= ',')\n",
    "# fuel_consumption_all_records      = pd.read_csv('../data/fuel_consumption_all_records.csv', delimiter= ',')\n",
    "# passengers_initial_300000_records = pd.read_csv('../data/passengers_initial_300000_records.csv', delimiter= ',')\n",
    "# flights_usa = pd.read_csv('../data/usa_flights2.csv', delimiter= ',')  # Terre is there a new csv to go with this one?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save working copies of the data:\n",
    "# df_fl_init    = flights_initial_500000_records.copy()\n",
    "# df_fl_delays  = flights_delay_dates_all_records.copy()\n",
    "df_fl_smpl1   = flights_random_100000_records.copy()\n",
    "# df_fl_smpl2   = flights_random_5000_records.copy()\n",
    "df_fl_test    = flights_test_all_records.copy()\n",
    "# df_fc         = fuel_consumption_all_records.copy()\n",
    "# df_pa_init    = passengers_initial_300000_records.copy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### SETUP:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_fl_smpl1.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Session stamp\n",
    "# tag = 'EDA1_' \n",
    "# dt = ''\n",
    "# session = f'{tag}{dt}'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### LOAD TABLE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flights\n",
    "print(f'\\nflights.shape: {df.shape}')\n",
    "display(df.head(3))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### NOTE: Missing Data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for nulls:\n",
    "# flights Table percent Null content:\n",
    "df_nulls = df.isnull().sum().sort_values(ascending= False)\n",
    "perc = (df.isnull().sum()/df.isnull().count()).sort_values(ascending = False)\n",
    "df_missing_data = pd.concat(\n",
    "    [df_nulls, perc]\n",
    "  , axis=1\n",
    "  , keys=['Total', 'Percent']\n",
    "  , verify_integrity= True\n",
    ")\n",
    "print(f'\\nflights_missing_data.head(20)')\n",
    "display(df_missing_data.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### NOTE: Differences between flights, and flights_test table data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fl_test_exclusion = df[df.columns[~df.columns.isin(df_fl_test.columns)]]\n",
    "fl_test_exclusion.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_columns = list(df.columns)\n",
    "flights_test_columns = list(df_fl_test.columns)\n",
    "fl_test_exclusion_columns = list(fl_test_exclusion.columns)\n",
    "unique_columns = list(set(flights_columns + flights_test_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(flights_columns))\n",
    "print(len(flights_test_columns))\n",
    "print(len(unique_columns))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DROP: rows with Null arr_delay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "df.dropna(subset= ['arr_delay'], inplace= True)\n",
    "print(df.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Isolate the columns that will be great predictors but will not be available 1 week before departure:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_of_delays = [\n",
    "    'carrier_delay',\n",
    "    'weather_delay',\n",
    "    'nas_delay',\n",
    "    'security_delay',\n",
    "    'late_aircraft_delay',\n",
    "    'dep_delay'\n",
    "]\n",
    "\n",
    "# 'taxi_in',                ???\n",
    "# 'taxi_out',               ???\n",
    "# 'wheels_on',              ???\n",
    "# 'wheels_off',             ???\n",
    "# 'total_add_gtime',        ???\n",
    "# 'longest_add_gtime',      ???\n",
    "# 'actual_elapsed_time',    ???"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DROP: columns not available to predict - 1 week.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "df = df.drop(columns=day_of_delays)\n",
    "print(df.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Starting with only the columns that are in the test table:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\n",
    "    'origin',\n",
    "    'dest',\n",
    "    'origin_airport_id',\n",
    "    'dest_airport_id',\n",
    "    'origin_city_name',\n",
    "    'dest_city_name',\n",
    "]].head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Airport code and ids are redundant, can drop one.  \n",
    "- City names are only useful if we want to extract the state codes for the models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\n",
    "    'flights',\n",
    "    'mkt_carrier',\n",
    "    'mkt_carrier_fl_num',\n",
    "    'mkt_unique_carrier',\n",
    "    'op_carrier_fl_num',\n",
    "    'op_unique_carrier',\n",
    "    'tail_num'\n",
    "]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Are the carrier codes ever different?\n",
    "carrier = df[['mkt_carrier','mkt_unique_carrier','op_unique_carrier']].copy()\n",
    "carrier['mkt_carrier'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "carrier.groupby(['mkt_carrier','mkt_unique_carrier'], as_index=False).count().sort_values('op_unique_carrier')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- mkt_carrier and mkt_unique_carrier appear to be duplicates. One can be dropped.\n",
    "- maybe keep to encode and see if there are delay related trends?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Is there ever more than one value under 'flights'?\n",
    "df['flights'].nunique()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 'flights' can be dropped, as it offers no unique info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do carrier flight numbers vary? and are they redundant with tail_num?\n",
    "plane_nums = df[[\n",
    "    'mkt_carrier_fl_num',\n",
    "    'op_carrier_fl_num',\n",
    "    'tail_num'\n",
    "]].copy()\n",
    "plane_nums.groupby(\n",
    "    ['mkt_carrier_fl_num', 'op_carrier_fl_num']\n",
    "    , as_index=False).count().sort_values('op_carrier_fl_num')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkt_diff = plane_nums[plane_nums['mkt_carrier_fl_num']!=plane_nums['op_carrier_fl_num']]\n",
    "print(mkt_diff.shape)\n",
    "mkt_diff"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12 rows of 100,000 not enough difference to care about.  \n",
    "- Drop one permanently, and \n",
    "- shuffle other two to later if we have time for advanced Feature Engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\n",
    "    'crs_arr_time',\n",
    "    'crs_dep_time',\n",
    "    'crs_elapsed_time',\n",
    "]].head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- These all appear unique and are numeric, so they're good to stay for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['branded_code_share'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_columns = [\n",
    "      'origin_airport_id'\n",
    "    , 'dest_airport_id'\n",
    "    , 'mkt_carrier'\n",
    "    , 'op_unique_carrier'\n",
    "    , 'branded_code_share'\n",
    "    , 'mkt_carrier_fl_num'\n",
    "    , 'tail_num'\n",
    "    , 'origin_city_name'\n",
    "    , 'dest_city_name'\n",
    "    , 'flights'\n",
    "    , 'op_carrier_fl_num'\n",
    "    , 'mkt_unique_carrier'\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DROP: columns either redundant, or without unique data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "df = df[df.columns[~df.columns.isin(drop_columns)]]\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\n",
    "'wheels_on',\n",
    "'wheels_off',\n",
    "'taxi_in',\n",
    "'taxi_out'\n",
    "]].head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are fine, but I wonder if wheels_on, wheels_off, taxi_in, and taxi_out are day-of items..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['first_dep_time'].value_counts().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\n",
    "    'air_time'\n",
    "  , 'first_dep_time'\n",
    "  , 'dep_time'\n",
    "  , 'arr_time'\n",
    "]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlikely = [\n",
    "    'air_time'\n",
    "  , 'first_dep_time'\n",
    "  , 'dep_time'\n",
    "]\n",
    "\n",
    "prob_also_day_of = [\n",
    "    'taxi_in'\n",
    "  , 'taxi_out'\n",
    "  , 'wheels_on'\n",
    "  , 'wheels_off'\n",
    "  , 'total_add_gtime'\n",
    "  , 'longest_add_gtime'\n",
    "  , 'actual_elapsed_time'\n",
    "]\n",
    "\n",
    "drop_columns = [\n",
    "    'dup'\n",
    "  , 'diverted'\n",
    "  , 'cancelled'\n",
    "  , 'cancellation_code'\n",
    "  , 'no_name'\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DROP: columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "df = df[df.columns[~df.columns.isin(\n",
    "      prob_also_day_of + drop_columns\n",
    "      )]]\n",
    "print(df.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary:\n",
    "\n",
    "- 'crs_arr_time',\n",
    "- 'crs_dep_time',\n",
    "- 'crs_elapsed_time',\n",
    "- 'origin',\n",
    "- 'dest',\n",
    "- 'distance',\n",
    "- 'fl_date',\n",
    "\n",
    "\n",
    "##### drop for now:\n",
    "Airport ids\n",
    "- 'origin_airport_id',\n",
    "- 'dest_airport_id',\n",
    "\n",
    "Carrier codes:\n",
    "- 'mkt_carrier', (&/or 'mkt_unique_carrier'),\n",
    "- 'op_unique_carrier',\n",
    "- 'branded_code_share',\n",
    "\n",
    "Flight mkt_carrier and tail nums:\n",
    "- 'mkt_carrier_fl_num', (&/or 'op_carrier_fl_num'),\n",
    "- 'tail_num',\n",
    "\n",
    "Possible feature engineering later:\n",
    "- 'origin_city_name',\n",
    "- 'dest_city_name',\n",
    "\n",
    "Maybe dropped forever:\n",
    "- 'flights',\n",
    "- 'op_carrier_fl_num',\n",
    "- 'mkt_unique_carrier'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NUMERIC ORDINAL ENCODING:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = set(list(df['origin']) + list(df['dest']))\n",
    "values = len(keys)\n",
    "airport_code_map = dict(zip(keys, range(values)))\n",
    "# airport_code_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['origin'] = df['origin'].map(airport_code_map)\n",
    "df['dest'] = df['dest'].map(airport_code_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OUTLIERS: 1.5 * IQR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the Arrival Delays:\n",
    "delays = df['arr_delay']\n",
    "\n",
    "# Define the quantiles of the delay distribution:\n",
    "Q1 = delays.quantile(0.25)\n",
    "Q3 = delays.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Define the outlier thresholds\n",
    "min_threshold = (Q1 - 1.5 * IQR)\n",
    "max_threshold = (Q3 + 1.5 * IQR)\n",
    "\n",
    "df = df[~((delays < min_threshold)|(delays > max_threshold))]\n",
    "df.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATETIME FEATURES:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert fl_date from string to datetime data type\n",
    "df[['fl_date']] = df[['fl_date']].apply(pd.to_datetime)\n",
    "\n",
    "df['year'] = df['fl_date'].dt.year\n",
    "df['month'] = df['fl_date'].dt.month\n",
    "df['day_of_wk'] = df['fl_date'].dt.dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SAVE CLEANED TABLE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../data/df_numeric.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "39512f3c2a1741d7f752d45a133d4514127029333ea14bc2f3c6c5e6759b9029"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
